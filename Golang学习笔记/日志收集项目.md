# 日志收集项目

> 已有的ELK方案缺点

- 部署的时候麻烦，每一个filebeat都需要配置一个配置文件

# 消息队列

> 把同步的函数调用函数，改成异步化
>
> 实现进程间的通信

## 通信模式

- 点对点模式：消息生产者生产消息发送到`queue`，消息消费者从`queue`中取出并消费消费。一条消息被消费后，`queue`中就没了，不存在重复消费
- 发布/订阅模式：生产者将消息发布到`topic`中，同时有多个消费者订阅消费该消息（发布到`topic`的消息会被所有订阅者消费）（可以看成是一个`topic`下有多个`queue`，每个`queue`是点对点，`queue`之间是发布订阅模式）

## Kafka介绍

> Kafka之所以比较快，是每条消息都有唯一标识offset，把物理磁盘的随机读改成了顺序读，效率很高

### 框架

![image-20210419142950782](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419142950782.png)

### 组件介绍

![image-20210419143047317](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419143047317.png)

![image-20210419144624233](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419144624233.png)

### 工作流程

> prodecer是生产者，是数据的入口，会把数据写入到`leader`中，不会直接写到`follower`中

![image-20210419143421653](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419143421653.png)

### 获取partition的原则

![image-20210419143704956](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419143704956.png)

### ACK应答机制

![image-20210419144004109](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419144004109.png)

### topic详解

- ![image-20210419145453271](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419145453271.png)

  ![image-20210419145503842](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419145503842.png)

### Kafka的数据保存

![image-20210419150036617](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419150036617.png)

### partition存储消息的原理

![image-20210419150141285](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419150141285.png)

### 消费消息的原理

![image-20210419150228586](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419150228586.png)

![image-20210419150556456](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419150556456.png)

## Kafka使用

- 修改配置

  - `zookeeper.properties`修改`dataDir=D:/tmp/zookeeper`
  - `server.properties`修改
    - `log.dirs=D:/tmp/kafka-logs`日志存放目录
    - `num.partitions=1`分区数量
    - `zookeeper.connect=localhost:2181`zookeeper连接的地址
    - 。。。

- 想要运行kafka需先运行ZooKeeper服务器

  ```powershell
  D:\kafka_2.13-2.7.0>bin\windows\zookeeper-server-start.bat config\zookeeper.properties
  ```

  - 报错`系统找不到指定的路径。`，需要修改`kafka-run-class.bat`的java环境变量

  - `zookeeper`在kafka中的作用，逐渐被etcd替代

    > Kafka集群的节点启动后，注册到zookeeper，用户连接Kafka集群的节点时，也是从zookeeper查询
    >
    > ![image-20210419162110089](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210419162110089.png)

    1. Broker注册
    2. Topic注册
    3. 生产者负载均衡 / 消费者负载均衡
    4. 分区与消费者的关系
    5. 消费进度Offset记录
    6. 消费者注册

- 启动kafka

  ```powershell
  D:\kafka_2.13-2.7.0>bin\windows\kafka-server-start.bat config\server.properties
  ```

- kafka终端读取数据

  ```powershell
  D:\kafka_2.13-2.7.0>bin\windows\kafka-console-consumer.bat --bootstrap-server=127.0.0.1:9092 --topic=web_log --from-beginning
  ```

## etcd介绍

### 概述

- 是Go开发的开源的分布式`key-value`存储系统，用于配置共享和服务的注册与 （类似的有zookeeper、consul等）
- 特点
  - 完全复制：集群中的每个节点都可使用完整的存档
  - 高可用：可用于避免硬件的单点故障或网络故障
  - 一致性：每次读取都会返回跨多主机的最新写入
  - 简单、安全（身份验证的自动化TLS）、可靠（Raft算法）
  - 快速：每秒1万次写入的基准速度

### raft算法

- 选举
- 日志复制机制
- 异常处理（脑裂）
- 和zookeeper的zad协议的区别

### 使用场景

#### 服务注册发现

![image-20210420104639543](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210420104639543.png)

#### 配置中心

![image-20210420105406279](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210420105406279.png)

#### 分布式锁

> 概念（待补充）

![image-20210420105438566](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210420105438566.png)

![image-20210420110044337](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210420110044337.png)

### 架构

![image-20210420110251798](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210420110251798.png)

![image-20210420110402573](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210420110402573.png)

### 集群

![image-20210420110506643](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210420110506643.png)

## etcd使用

- 启动服务端：直接启动.exe就行，默认2379端口监听客户端通信，2380端口监听一个集群中节点间通信
- 启动客户端：`etcdctl.exe put zhangsan dsb --endpoints=127.0.0.1:2379`

## ES介绍

> Elastic Search，开源的搜索引擎
>
> shards是分片，hits是纪录

![image-20210421211925349](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210421211925349.png)

- 启动后在浏览器输入本机ip+9200端口号
- 以上地址后面跟如下字段，可以进行不同的操作
  - `/_cat/health`查看健康状态，GTE请求
  - `/_cat/indices`获取集群所有的indices，GET请求
  - PUT请求可以用`postman`工具
  - 查询需要构造json语句后，发GET请求，地址后面跟`/_search`

> Go操作ES

- `go get github.com/olivere/elastic`

  ```go
  put1, err := client.Index().
  	Index("student").
  	Type("go").
  	BodyJson(p1).// 必须是json或能转成json的数据
  	Do(context.Background())
  ```

## Kibana介绍

> 版本要和ES兼容

- `kibana.yml`中改`i18n.locale: "zh-CN"`和`elasticsearch.hosts: ["http://localhost:9200"]`
- 启动`bin\kibana.bat`后在浏览器输入`http://127.0.0.1:5601/`

# 项目模块

## LogAgent

### 工作流程

1. 解析配置文件，`kafka`和`etcd`的`ip`地址、连接超时的时间（`go-ini/ini`第三方库）

2. 初始化`kafka`连接

3. 初始化`etcd`

   1. 从`etcd`根据`key`获取配置：日志路径和`topic`
   2. 派一个哨兵去监视配置信息的变化，有变化及时通知`LogAgent`实现配置热加载
      - 做一个task的管理者，里面包含value类型为task的map、配置项的切片、存放配置信息变化的通道
      - 做一个函数来监听这个通道，有新配置过来后就做对应的处理（增、删、改）

4. 跟踪日志文件（`tailf`第三方库），每新增一行，往`kafka`写一条消息（`sarama`第三方库）

   1. 遍历每一个配置项（日志文件的路径和`topic`构成一个配置），创建对应的`Tailobj`

      - 当需要一个`obj`对应一个配置项的结构体变量时，可以做一个管理所有`obj`的结构体（task）

      - 每`new`一个`task`，就把配置项中的路径和`topic`传递给`task`，和`obj`绑定起来

        > 因为在`Init`过程中，`tail.TailFile()`需要日志文件的路径，直接把路径传参给`Init`不利于后续演进

   2. 遍历`TailObj.Lines`，将读到的每一行日志发往`kafka`

      - 遍历配置项往`kafka`发的过程不要放到`main`函数中，包装起来
      - 包装后，异步发往kafka，暴露给外部调用的发送消息的函数只是把消息存到一个100000容量的通道中
      - `Init`中启一个`goroutine`来单独发往kafka

## Logtransfer

> 从kafka里把日志取出来，写入ES，使用kibana做可视化的展示

### 工作流程

1. 加载配置文件，kafka、es的ip地址，kafka的topic
2. 初始化ES
   - 连接ES
   - 对外提供一个往ES写数据的函数
3. 初始化kafka
   - 连接kafka，创建分区的消费者
   - 每个分区的消费者分别取出数据，发往ES

## 系统监控

- `gopsutil`做系统监控信息的采集，写入`influxDB`，使用`grafana`做展示

  > 一般几十毫秒采集一次，不存到mysql中，一般存到`influxDB`中（时序数据库）

  - `gopsutil/cpu`，`cpu.Info()`、`cpu.Percent()`：cpu的信息、使用率

  - `gopsutil/load`，`load.Avg()`：负载信息

  - `gopsutil/mem`，`mem.VirtualMemory()`：虚拟内存信息

  - `gopsutil/host`，先获取`host.Info()`、再获取`Info().Uptime()`、`host.Info().BootTime()`：主机信息

  - `gopsutil/disk`

    ```go
    parts, err := disk.Partitions(true) // 磁盘的所有分区信息
    for _, part := parts {
        可以打印part.String()
        diskInfo, _ := disk.Usage(part.Mountpoint) // 挂载点的使用情况
        可以打印diskInfo.UsedPercend, diskInfo.Free //使用率、空闲率
    }
    ioStat, _ := disk.IOCounters() // 是个map
    ```

  - `gopsutil/net`，`net.IOCounters(true)`，遍历此map，可得到`v.BytesSent`、`v.BytesRecv`

- `prometheus`监控：采集性能指标数据并存储，使用`grafana`展示

  ![image-20210422162935947](D:\资料\Go\src\studygo\Golang学习笔记\日志收集项目.assets\image-20210422162935947.png)

# 作业

1. Raft协议
   - 选举
   - 日志复制机制
   - 异常处理（脑裂）
   - 和zookeeper的zad协议的区别
2. etcd的watch
   - 底层是怎么实现的watch给客户端发通知
3. 为什么不用ELK

总结

- 项目的架构（图）
- 为什么不用ELK
- LogAgent里面如何保证日志不丢/重启之后继续收集日志（记录读取文件的offset）
- kafka知识点
- etcd的watch原理
- es知识点